# StyleTransfer

For centuries, the possession of art has been attributed
to skilled artists. To emulate an artist, one must possess
exceptional abilities and dedicate a significant amount of
time. That is why artists such as Picasso and Van Gogh
are held in such high regard. In the past, computer scientists have explored various methods and studies pertaining to the automatic conversion of images into artificial artworks. With the evolution of computer science, particularly
through the development of Convolutional Neural Networks
(CNNs) introduced by Gatsys et al., the concept of neural
style transfer (NST) has revolutionized the automatic conversion of images into artificial artworks. This technique
allows for the blending of a photograph’s content with the
style of renowned artworks, iteratively optimizing an image to match the feature distributions of a pre-trained CNN.
A primary challenge in this field is dynamically applying
multiple styles to a content image without the need for separate models for each style. My study involved exploring various methods such as the use of TensorFlow Hub’s
pre-trained magenta model with an Adaptive Instance Normalization (AdaIN) layer, Multi-style Generative Network
(MSG-Net), and CLIPstyler, which utilizes text-image alignment for style manipulation. Additional experiments with
Multi-style GANs and transformers were conducted to assess their efficacy in real-time, dynamic style transfer. This
analysis aimed to determine the most effective method to
accurately replicate iconic artistic styles, enhancing digital
art creation and educational tools.

### Please read the project report for detailed information
